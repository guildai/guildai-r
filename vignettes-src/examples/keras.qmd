---
title: "example_keras"
---

```{r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE)

# set up a "project" directory for render
root.dir <- tempfile("guildai-sample-keras-project-")
dir.create(root.dir)
dir.create(file.path(root.dir, ".guild"))
file.copy("train-keras.R", root.dir)
knitr::opts_knit$set(root.dir = root.dir)

# help knitr capture stdout
ns <- asNamespace("guildai")
unlockBinding("system2t", ns)
ns$system2t <- function(command, args, ..., stdout = "", stderr = "" ) {
  if(stdout == "" && stderr == "") {
    stdout <- stderr <- TRUE
    on.exit(writeLines(out))
  }
  out <- base::system2(command, args, stdout = stdout, stderr=stderr, ...)
  invisible(out)
}
options(guildai.run_as_job = FALSE)

Sys.setenv("TF_CPP_MIN_LOG_LEVEL" = "3")

```

Here is an example showing how to use *guildai* with TensorFlow and
Keras in R.

If this is your first exposure to *guildai*, we recommend starting with
the framework agnostic "Getting Started" guide. This example assumes
familiarity with guild concepts like *flags* and *scalars*.

We'll start with an example R script, named "train.R", that trains,
evaluates, and saves a Keras model using the fashion mnist dataset. Here
is what it looks like:

```{r, file = "train-keras.R", eval = FALSE}
```

A few things to note about the script:

-   There is no 'guildai' specific configuration anywhere in the script.
    It's a regular R script, that you would normally `source()`.
-   Flags like `batch_size`, `epochs`, and `units` are can be defined
    anywhere in the script. We take advantage of this by defining flags
    close to their point of use.
-   `callback_tensorboard()` in the list of callbacks provided to the
    `fit()` call will result in tfevent records being written during
    training. Guild will automatically parse these logs for scalars.
-   In addition to the tensorboard logs, we are also directly printing
    two scalars named `test_loss` and `test_accuracy` to stdout.
-   At the end of the run, we save the model and training history. These
    file artifacts will be stored as part of the run, enabling us to
    restore a trained model.

With our script defined, we can launch a guild run:

```{r}
library(guildai)
guild_run("train-keras.R")
```

Inspecting the run flags and scalars:

```{r, paged.print = FALSE}
run <- runs_info(1)
str(run$flags)
str(run$scalars)
```

`runs_info()` returns the last value for each scalar. The full history
of scalars emitted is available with `runs_scalars()`.

```{r, paged.print = FALSE}
all_scalars <- runs_scalars(1)

all_scalars |>
  dplyr::arrange(step)
```

We can plot scalars vs step for the full training history:

```{r}
library(dplyr)
library(ggplot2)

all_scalars %>%
  filter(tag %in% c("epoch_accuracy", "epoch_loss")) %>% 
  mutate(tag = forcats::fct_rev(tag)) %>% 
  ggplot(aes(x = step, y = value, color = path)) + 
  facet_grid(rows = vars(tag), switch = 'y', scales = 'free_y') +
  geom_point() + geom_smooth(se = FALSE)
```

We can compare this to the `history` object from `fit()` we saved in the
run. It is indeed the same.

```{r}
list.files(run$dir)

history <- readRDS(file.path(run$dir, "history.rds"))
library(keras) # to load the plot.keras_training_history() method
plot(history)
```

Finally, we can load the model trained during the run by accessing the
saved files directly.

```{r}
model <- load_model_tf(file.path(run$dir, "model.keras"))
model
```
